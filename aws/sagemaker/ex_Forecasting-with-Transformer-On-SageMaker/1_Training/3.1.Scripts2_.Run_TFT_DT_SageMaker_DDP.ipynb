{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4b27d946-a068-458a-9a19-a4e1f4abfcf0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# [모듈 3.1] 세이지메이커에서 멀티 노트 분산 훈련 하기\n",
    "\n",
    "이 노트북은 커널을 'conda_python3' 를 사용합니다.\n",
    "\n",
    "---\n",
    "아래와 같이 pytorchddp 를 백엔드로 해서 2개의 \"ml.p3.8xlarge\" 로 학습합니다.\n",
    "\n",
    "```\n",
    "    distribution={\"pytorchddp\":{\"enabled\": True}},    \n",
    "    instance_count=2,\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7444f2fd-db36-4489-a066-8bca587dc171",
   "metadata": {},
   "source": [
    "# 1. 환경 설정\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27b9bd08-1fe9-4306-ae4b-8cd0a99ac564",
   "metadata": {},
   "source": [
    "## 기본 세팅\n",
    "사용하는 패키지는 import 시점에 다시 재로딩 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5e68172-0ed2-448b-ad99-0659323e4848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append('./scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97204ea5-68c0-4f1e-8dec-0318772d38a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sagemaker.__version__\n",
    "\n",
    "# sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772a23fa-eee6-4b29-945e-751105551487",
   "metadata": {},
   "source": [
    "## 파라미터 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f41139d8-0a16-4a4b-874e-895745acd082",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs:  1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "epochs = 1\n",
    "print(\"epochs: \", epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bcda9-79ef-4f79-9721-ee13e2618439",
   "metadata": {},
   "source": [
    "# 2. 세이지 메이크 로컬 모드 훈련\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d914a093-c1fc-4676-91b1-02f05ce3c160",
   "metadata": {},
   "source": [
    "## 로컬 모드로 실행 여부\n",
    "- False 이면 실행 안함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56246435-e178-4c42-94c6-203de3dbb8fc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "local_mode = True "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f692abd-cae4-438b-9187-99f2bed200fc",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 로컬의 GPU, CPU 여부로 instance_type 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07a8e179-f1a7-40b3-a275-fcba9bf11ede",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Mar  4 14:17:21 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla V100-SXM2...  On   | 00000000:00:17.0 Off |                    0 |\n",
      "| N/A   28C    P0    40W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   1  Tesla V100-SXM2...  On   | 00000000:00:18.0 Off |                    0 |\n",
      "| N/A   27C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   2  Tesla V100-SXM2...  On   | 00000000:00:19.0 Off |                    0 |\n",
      "| N/A   27C    P0    38W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   3  Tesla V100-SXM2...  On   | 00000000:00:1A.0 Off |                    0 |\n",
      "| N/A   28C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   4  Tesla V100-SXM2...  On   | 00000000:00:1B.0 Off |                    0 |\n",
      "| N/A   27C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   5  Tesla V100-SXM2...  On   | 00000000:00:1C.0 Off |                    0 |\n",
      "| N/A   27C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   6  Tesla V100-SXM2...  On   | 00000000:00:1D.0 Off |                    0 |\n",
      "| N/A   28C    P0    41W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "|   7  Tesla V100-SXM2...  On   | 00000000:00:1E.0 Off |                    0 |\n",
      "| N/A   27C    P0    43W / 300W |      3MiB / 16384MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n",
      "Instance type = local_gpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "\n",
    "try:\n",
    "    if subprocess.call(\"nvidia-smi\") == 0:\n",
    "        ## Set type to GPU if one is present\n",
    "        instance_type = \"local_gpu\"\n",
    "    else:\n",
    "        instance_type = \"local\"        \n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"Instance type = \" + instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e25ed9c-3f2a-40b1-ae9b-6ec7b8b8687f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 로컬 모드로 훈련 실행\n",
    "- 아래의 두 라인이 로컬모드로 훈련을 지시 합니다.\n",
    "```python\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdb1893b-20a3-4867-bdac-eec5206e1867",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyperparameters = {'epochs': epochs, \n",
    "                    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e76fe8b-e1ed-4438-8d2d-3a662f37c558",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-03-04-14-17-21-759\n",
      "INFO:sagemaker.local.local_session:Starting training job\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.local.image:No AWS credentials found in session but credentials from EC2 Metadata Service are available.\n",
      "INFO:sagemaker.local.image:docker compose file: \n",
      "networks:\n",
      "  sagemaker-local:\n",
      "    name: sagemaker-local\n",
      "services:\n",
      "  algo-1-rc30d:\n",
      "    command: train\n",
      "    container_name: n3a77bo8pk-algo-1-rc30d\n",
      "    deploy:\n",
      "      resources:\n",
      "        reservations:\n",
      "          devices:\n",
      "          - capabilities:\n",
      "            - gpu\n",
      "    environment:\n",
      "    - '[Masked]'\n",
      "    - '[Masked]'\n",
      "    image: 763104351884.dkr.ecr.us-east-1.amazonaws.com/pytorch-training:1.12.1-gpu-py38\n",
      "    networks:\n",
      "      sagemaker-local:\n",
      "        aliases:\n",
      "        - algo-1-rc30d\n",
      "    stdin_open: true\n",
      "    tty: true\n",
      "    volumes:\n",
      "    - /tmp/tmpflvadli6/algo-1-rc30d/output:/opt/ml/output\n",
      "    - /tmp/tmpflvadli6/algo-1-rc30d/output/data:/opt/ml/output/data\n",
      "    - /tmp/tmpflvadli6/algo-1-rc30d/input:/opt/ml/input\n",
      "    - /tmp/tmpflvadli6/model:/opt/ml/model\n",
      "    - /opt/ml/metadata:/opt/ml/metadata\n",
      "version: '2.3'\n",
      "\n",
      "INFO:sagemaker.local.image:docker command: docker-compose -f /tmp/tmpflvadli6/docker-compose.yaml up --build --abort-on-container-exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating n3a77bo8pk-algo-1-rc30d ... \n",
      "Creating n3a77bo8pk-algo-1-rc30d ... done\n",
      "Attaching to n3a77bo8pk-algo-1-rc30d\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,446 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,511 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,521 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,523 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,531 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,531 sagemaker_pytorch_container.training INFO     Invoking user training script.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,594 botocore.credentials INFO     Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:25,799 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m /opt/conda/bin/python3.8 -m pip install -r requirements.txt\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pytorch-forecasting==0.10.3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 5.7 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pytorch-lightning==1.6.3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 584.0/584.0 kB 47.1 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pyarrow==11.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (11.0.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting tensorboard==2.12.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 82.6 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting statsmodels\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 87.5 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting scikit-learn<1.2,>=0.24\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.2/31.2 MB 53.5 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: torch<2.0,>=1.7 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.12.1+cu113)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: scipy<2.0,>=1.8 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.10.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pandas<2.0.0,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.5.3)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.7.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting optuna<3.0.0,>=2.3.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading optuna-2.10.1-py3-none-any.whl (308 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.2/308.2 kB 37.4 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting torchmetrics>=0.4.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 518.6/518.6 kB 49.3 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (2023.1.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (23.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (1.23.5)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (5.4.1)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.64.1)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pyDeprecate<0.4.0,>=0.3.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.4.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting grpcio>=1.48.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 87.6 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting google-auth<3,>=1.6.3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.2/177.2 kB 27.4 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting markdown>=2.6.8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading Markdown-3.4.1-py3-none-any.whl (93 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 16.0 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.2.3)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (0.38.4)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.28.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting absl-py>=0.4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 19.3 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (3.20.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (65.6.3)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting tensorboard-plugin-wit>=1.6.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 61.4 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 91.1 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 66.3 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.16.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.7.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting cachetools<6.0,>=2.0.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pyasn1-modules>=0.2.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 26.1 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting requests-oauthlib>=0.7.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.13.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting alembic\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading alembic-1.9.4-py3-none-any.whl (210 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.5/210.5 kB 30.4 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting cliff\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading cliff-4.2.0-py3-none-any.whl (81 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 13.6 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting cmaes>=0.8.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading cmaes-0.9.1-py3-none-any.whl (21 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting sqlalchemy>=1.1.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading SQLAlchemy-2.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 87.6 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting colorlog\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.8.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2022.7.1)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.26.14)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.1)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.4)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2022.12.7)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.1.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.2.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.0.7)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (5.10.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.0.9)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.11.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.4.4)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (9.4.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (4.38.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting patsy>=0.5.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 34.3 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (22.2.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting multidict<7.0,>=4.5\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 18.2 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting async-timeout<5.0,>=4.0.0a3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting frozenlist>=1.1.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 25.8 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting yarl<2.0,>=1.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 33.2 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting aiosignal>=1.1.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.13.0)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (0.4.8)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting oauthlib>=3.0.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 23.9 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.0.2)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting Mako\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading Mako-1.2.4-py3-none-any.whl (78 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 13.9 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting PrettyTable>=0.7.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading prettytable-3.6.0-py3-none-any.whl (27 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting cmd2>=1.0.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading cmd2-2.4.3-py3-none-any.whl (147 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.2/147.2 kB 22.7 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting autopage>=0.4.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading autopage-0.5.1-py3-none-any.whl (29 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting stevedore>=2.0.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading stevedore-5.0.0-py3-none-any.whl (49 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 kB 7.8 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Requirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.2.6)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pyperclip>=1.6\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pyperclip-1.8.2.tar.gz (20 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Preparing metadata (setup.py): started\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Preparing metadata (setup.py): finished with status 'done'\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Collecting pbr!=2.1.0,>=2.0.0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Downloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.7/112.7 kB 19.6 MB/s eta 0:00:00\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Building wheels for collected packages: pyperclip\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Building wheel for pyperclip (setup.py): started\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Building wheel for pyperclip (setup.py): finished with status 'done'\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Created wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=7bf4a915198a85c241621a8bb60bac0e18677b5bea3963a6b4e0d527902c2185\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Stored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Successfully built pyperclip\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Installing collected packages: tensorboard-plugin-wit, pyperclip, tensorboard-data-server, sqlalchemy, pyDeprecate, pyasn1-modules, PrettyTable, pbr, patsy, oauthlib, multidict, Mako, grpcio, frozenlist, colorlog, cmd2, cmaes, cachetools, autopage, async-timeout, absl-py, yarl, torchmetrics, stevedore, scikit-learn, requests-oauthlib, markdown, google-auth, alembic, aiosignal, statsmodels, google-auth-oauthlib, cliff, aiohttp, tensorboard, optuna, pytorch-lightning, pytorch-forecasting\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Attempting uninstall: scikit-learn\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Found existing installation: scikit-learn 1.2.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Uninstalling scikit-learn-1.2.1:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Successfully uninstalled scikit-learn-1.2.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Successfully installed Mako-1.2.4 PrettyTable-3.6.0 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.9.4 async-timeout-4.0.2 autopage-0.5.1 cachetools-5.3.0 cliff-4.2.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 frozenlist-1.3.3 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 markdown-3.4.1 multidict-6.0.4 oauthlib-3.2.2 optuna-2.10.1 patsy-0.5.3 pbr-5.11.1 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pyperclip-1.8.2 pytorch-forecasting-0.10.3 pytorch-lightning-1.6.3 requests-oauthlib-1.3.1 scikit-learn-1.1.3 sqlalchemy-2.0.4 statsmodels-0.13.5 stevedore-5.0.0 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 torchmetrics-0.11.3 yarl-1.8.2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [notice] A new release of pip is available: 23.0 -> 23.0.1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [notice] To update, run: pip install --upgrade pip\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,620 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,621 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,690 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,701 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,772 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,782 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,785 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,785 sagemaker-training-toolkit INFO     Creating SSH daemon.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,787 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,787 sagemaker-training-toolkit INFO     Network interface name: eth0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,787 sagemaker-training-toolkit INFO     Host: ['algo-1-rc30d']\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,789 sagemaker-training-toolkit INFO     sagemaker_communication_backend: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,789 sagemaker-training-toolkit WARNING  Missing library /opt/conda/lib/libsmddp.so for SMDDP collective\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,789 sagemaker-training-toolkit WARNING  The system is not configured to run SMDDP collectives optimizedfor AWS infrastructure.Please use the latest SageMaker Deep Learning Container (DLC) to enable SMDDP Collectives support.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Continuing model training with default NCCL communication backend.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,789 sagemaker-training-toolkit INFO     instance type: local_gpu\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,789 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1-rc30d'] Hosts: ['algo-1-rc30d'] process_per_hosts: 8 num_processes: 8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,857 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,867 sagemaker-training-toolkit INFO     instance_groups entry not present in resource_config\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:17:48,871 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Training Env:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m {\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"additional_framework_parameters\": {\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"sagemaker_pytorch_ddp_enabled\": true,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"sagemaker_instance_type\": \"local_gpu\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     },\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"channel_input_dirs\": {},\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"current_host\": \"algo-1-rc30d\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"current_instance_group\": \"homogeneousCluster\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"current_instance_group_hosts\": [],\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"current_instance_type\": \"local\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"distribution_hosts\": [\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"algo-1-rc30d\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     ],\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"distribution_instance_groups\": [\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"homogeneousCluster\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     ],\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"algo-1-rc30d\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     ],\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"epochs\": 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     },\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"input_data_config\": {},\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"instance_groups\": [],\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"instance_groups_dict\": {},\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"is_hetero\": false,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"is_modelparallel_enabled\": null,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"is_smddpmprun_installed\": true,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"job_name\": \"pytorch-training-2023-03-04-14-17-21-759\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"master_hostname\": \"algo-1-rc30d\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-17-21-759/source/sourcedir.tar.gz\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"module_name\": \"TFT_Train_SM_DDP\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"num_cpus\": 64,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"num_gpus\": 8,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"num_neurons\": 0,\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"current_host\": \"algo-1-rc30d\",\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m             \"algo-1-rc30d\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m         ]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     },\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m     \"user_entry_point\": \"TFT_Train_SM_DDP.py\"\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m }\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Environment variables:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_HOSTS=[\"algo-1-rc30d\"]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_HPS={\"epochs\":1}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_USER_ENTRY_POINT=TFT_Train_SM_DDP.py\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"local_gpu\",\"sagemaker_pytorch_ddp_enabled\":true}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-rc30d\",\"hosts\":[\"algo-1-rc30d\"]}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_INPUT_DATA_CONFIG={}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_CHANNELS=[]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_CURRENT_HOST=algo-1-rc30d\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_CURRENT_INSTANCE_TYPE=local\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_CURRENT_INSTANCE_GROUP=homogeneousCluster\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_CURRENT_INSTANCE_GROUP_HOSTS=[]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_INSTANCE_GROUPS=[]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_INSTANCE_GROUPS_DICT={}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_IS_HETERO=false\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_MODULE_NAME=TFT_Train_SM_DDP\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_NUM_CPUS=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_NUM_GPUS=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_NUM_NEURONS=0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-17-21-759/source/sourcedir.tar.gz\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"local_gpu\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{},\"current_host\":\"algo-1-rc30d\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[],\"current_instance_type\":\"local\",\"distribution_hosts\":[\"algo-1-rc30d\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1-rc30d\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[],\"instance_groups_dict\":{},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2023-03-04-14-17-21-759\",\"log_level\":20,\"master_hostname\":\"algo-1-rc30d\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-17-21-759/source/sourcedir.tar.gz\",\"module_name\":\"TFT_Train_SM_DDP\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-rc30d\",\"hosts\":[\"algo-1-rc30d\"]},\"user_entry_point\":\"TFT_Train_SM_DDP.py\"}\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_USER_ARGS=[\"--epochs\",\"1\"]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m SM_HP_EPOCHS=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m PYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/flash_attn-0.1-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/einops-0.6.0-py3.8.egg\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m mpirun --host algo-1-rc30d -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 1 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_SINGLENODE=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x USE_SMDDP_COLLECTIVES=0 smddprun /opt/conda/bin/python3.8 -m mpi4py TFT_Train_SM_DDP.py --epochs 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Not running on notebook\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:***** Arguments *****\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:epochs=1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:seed=100\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:train_batch_size=64\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:model_dir=/opt/ml/model\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:n_gpus=8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:num_nodes=16\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:world_size=128\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:GPU available: True, used: True\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:TPU available: False, using: 0 TPU cores\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:IPU available: False, using: 0 IPUs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:HPU available: False, using: 0 HPUs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:Number of parameters in network: 29.7k\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:distributed_backend=nccl\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:All distributed processes registered. Starting with 8 processes\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:161 [2] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:173 [6] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:158 [1] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:166 [4] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:169 [5] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:174 [7] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO Bootstrap : Using eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO NET/Socket : Using [0]eth0:172.18.0.2<0>\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:164 [3] NCCL INFO Using network Socket\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Trees [0] 6/-1/-1->5->1 [1] 6/-1/-1->5->1 [2] 1/-1/-1->5->6 [3] 1/-1/-1->5->6 [4] 4/-1/-1->5->7 [5] 7/-1/-1->5->4 [6] 6/-1/-1->5->1 [7] 6/-1/-1->5->1 [8] 1/-1/-1->5->6 [9] 1/-1/-1->5->6 [10] 4/-1/-1->5->7 [11] 7/-1/-1->5->4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5 [2] 5/-1/-1->6->7 [3] 5/-1/-1->6->7 [4] 2/-1/-1->6->4 [5] 4/-1/-1->6->2 [6] 7/-1/-1->6->5 [7] 7/-1/-1->6->5 [8] 5/-1/-1->6->7 [9] 5/-1/-1->6->7 [10] 2/-1/-1->6->4 [11] 4/-1/-1->6->2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Trees [0] 4/-1/-1->7->6 [1] 4/-1/-1->7->6 [2] 6/-1/-1->7->4 [3] 6/-1/-1->7->4 [4] 5/-1/-1->7->3 [5] 3/-1/-1->7->5 [6] 4/-1/-1->7->6 [7] 4/-1/-1->7->6 [8] 6/-1/-1->7->4 [9] 6/-1/-1->7->4 [10] 5/-1/-1->7->3 [11] 3/-1/-1->7->5\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 00/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 01/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 02/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 03/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 04/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Trees [0] 5/-1/-1->1->2 [1] 5/-1/-1->1->2 [2] 2/-1/-1->1->5 [3] 2/-1/-1->1->5 [4] 3/-1/-1->1->0 [5] -1/-1/-1->1->3 [6] 5/-1/-1->1->2 [7] 5/-1/-1->1->2 [8] 2/-1/-1->1->5 [9] 2/-1/-1->1->5 [10] 3/-1/-1->1->0 [11] -1/-1/-1->1->3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 05/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 06/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Trees [0] 1/-1/-1->2->3 [1] 1/-1/-1->2->3 [2] 3/-1/-1->2->1 [3] 3/-1/-1->2->1 [4] -1/-1/-1->2->6 [5] 6/-1/-1->2->0 [6] 1/-1/-1->2->3 [7] 1/-1/-1->2->3 [8] 3/-1/-1->2->1 [9] 3/-1/-1->2->1 [10] -1/-1/-1->2->6 [11] 6/-1/-1->2->0\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 07/12 :    0   3   2   1   5   6   7   4\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 08/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 09/12 :    0   4   7   6   5   1   2   3\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Trees [0] 2/-1/-1->3->0 [1] 2/-1/-1->3->0 [2] -1/-1/-1->3->2 [3] -1/-1/-1->3->2 [4] 7/-1/-1->3->1 [5] 1/-1/-1->3->7 [6] 2/-1/-1->3->0 [7] 2/-1/-1->3->0 [8] -1/-1/-1->3->2 [9] -1/-1/-1->3->2 [10] 7/-1/-1->3->1 [11] 1/-1/-1->3->7\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Trees [0] -1/-1/-1->4->7 [1] -1/-1/-1->4->7 [2] 7/-1/-1->4->0 [3] 7/-1/-1->4->0 [4] 6/-1/-1->4->5 [5] 5/-1/-1->4->6 [6] -1/-1/-1->4->7 [7] -1/-1/-1->4->7 [8] 7/-1/-1->4->0 [9] 7/-1/-1->4->0 [10] 6/-1/-1->4->5 [11] 5/-1/-1->4->6\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 10/12 :    0   1   3   7   5   4   6   2\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 11/12 :    0   2   6   4   5   7   3   1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Trees [0] 3/-1/-1->0->-1 [1] 3/-1/-1->0->-1 [2] 4/-1/-1->0->-1 [3] 4/-1/-1->0->-1 [4] 1/-1/-1->0->-1 [5] 2/-1/-1->0->-1 [6] 3/-1/-1->0->-1 [7] 3/-1/-1->0->-1 [8] 4/-1/-1->0->-1 [9] 4/-1/-1->0->-1 [10] 1/-1/-1->0->-1 [11] 2/-1/-1->0->-1\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 04 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 10 : 0[170] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 02 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 05 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 03 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 11 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 06 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 08 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 07 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 09 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 06 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 02 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 07 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 03 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 04 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 08 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 05 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 10 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 11 : 0[170] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 09 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 05 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 11 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 04 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 10 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 02 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 03 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 04 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 08 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 00 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 02 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 10 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 09 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 01 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 03 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 06 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 05 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 08 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 00 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 11 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 07 : 0[170] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 09 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 01 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 06 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 07 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 05 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 05 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 04 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 11 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 10 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 11 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 00 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 04 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 01 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 10 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 06 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 02 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 07 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 03 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 08 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 00 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 02 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 09 : 0[170] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 03 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 01 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 08 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 06 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 09 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 07 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 04 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 05 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 10 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 11 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 02 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 00 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 03 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 01 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 08 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 06 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 09 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 07 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 02 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 04 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 00 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 05 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 03 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 10 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 01 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 11 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 08 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 06 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 09 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 07 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 04 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 10 : 4[1b0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 00 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Connected all rings\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 01 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 02 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 06 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 03 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 07 : 1[180] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 08 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 09 : 5[1c0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 02 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 00 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 03 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 01 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 08 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 06 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 05 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 09 : 6[1d0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 11 : 4[1b0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 07 : 2[190] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 05 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 04 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 11 : 1[180] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 10 : 5[1c0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 04 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 00 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 10 : 2[190] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 05 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 01 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 11 : 3[1a0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 05 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 06 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 02 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 00 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 11 : 6[1d0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 07 : 4[1b0] -> 7[1e0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 03 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 01 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 08 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 06 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 09 : 1[180] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 07 : 5[1c0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 04 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 05 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 02 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 10 : 6[1d0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 11 : 2[190] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 03 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 04 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 08 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 10 : 7[1e0] -> 3[1a0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 09 : 4[1b0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 02 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 00 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 03 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 01 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 08 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 06 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 09 : 7[1e0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 07 : 3[1a0] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 05 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 04 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 11 : 7[1e0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 10 : 3[1a0] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 02 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 03 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 06 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 08 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 07 : 7[1e0] -> 6[1d0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 09 : 3[1a0] -> 2[190] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 05 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 02 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 04 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 11 : 5[1c0] -> 4[1b0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 03 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 10 : 1[180] -> 0[170] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 06 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 08 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 07 : 6[1d0] -> 5[1c0] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 09 : 2[190] -> 1[180] via P2P/IPC\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Connected all trees\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 01 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 01 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 09 : 7[1e0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO 12 coll channels, 16 p2p channels, 2 p2p channels per peer\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 02 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 09 : 3[1a0] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 10 : 6[1d0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 02 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 02 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 10 : 7[1e0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 02 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 10 : 2[190] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 10 : 3[1a0] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 03 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO Channel 11 : 7[1e0] -> 2[190] via P2P/indirect/3[1a0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 03 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 03 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO Channel 11 : 3[1a0] -> 6[1d0] via P2P/indirect/7[1e0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 11 : 1[180] -> 4[1b0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 03 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 03 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 11 : 6[1d0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 03 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 11 : 2[190] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 05 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 11 : 5[1c0] -> 0[170] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 13 : 4[1b0] -> 1[180] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 05 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 05 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 13 : 0[170] -> 5[1c0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 13 : 1[180] -> 6[1d0] via P2P/indirect/5[1c0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 05 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 05 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO Channel 13 : 6[1d0] -> 3[1a0] via P2P/indirect/2[190]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 05 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 13 : 5[1c0] -> 2[190] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 06 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO Channel 13 : 2[190] -> 7[1e0] via P2P/indirect/6[1d0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 06 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 14 : 4[1b0] -> 2[190] via P2P/indirect/6[1d0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 06 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 14 : 0[170] -> 6[1d0] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO Channel 14 : 1[180] -> 7[1e0] via P2P/indirect/3[1a0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 06 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO Channel 14 : 5[1c0] -> 3[1a0] via P2P/indirect/1[180]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 07 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 07 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO Channel 15 : 0[170] -> 7[1e0] via P2P/indirect/4[1b0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO Channel 15 : 4[1b0] -> 3[1a0] via P2P/indirect/0[170]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:algo-1-rc30d:158:1059 [1] NCCL INFO comm 0x7f7aa0003010 rank 1 nranks 8 cudaDev 1 busId 180 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:algo-1-rc30d:161:1058 [2] NCCL INFO comm 0x7f9c88003010 rank 2 nranks 8 cudaDev 2 busId 190 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:1056 [0] NCCL INFO comm 0x7f90bc003010 rank 0 nranks 8 cudaDev 0 busId 170 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:algo-1-rc30d:173:1057 [6] NCCL INFO comm 0x7f4ea4003010 rank 6 nranks 8 cudaDev 6 busId 1d0 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:algo-1-rc30d:169:1061 [5] NCCL INFO comm 0x7f815c003010 rank 5 nranks 8 cudaDev 5 busId 1c0 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:algo-1-rc30d:164:1063 [3] NCCL INFO comm 0x7fd928003010 rank 3 nranks 8 cudaDev 3 busId 1a0 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:algo-1-rc30d:174:1062 [7] NCCL INFO comm 0x7fcfa0003010 rank 7 nranks 8 cudaDev 7 busId 1e0 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:algo-1-rc30d:166:1060 [4] NCCL INFO comm 0x7fc2b0003010 rank 4 nranks 8 cudaDev 4 busId 1b0 - Init COMPLETE\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:algo-1-rc30d:634:634 [0] NCCL INFO Launch mode Parallel\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stderr>:LOCAL_RANK: 6 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stderr>:LOCAL_RANK: 4 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stderr>:LOCAL_RANK: 7 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stderr>:LOCAL_RANK: 5 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3,4,5,6,7]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:   | Name                               | Type                            | Params\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:0  | loss                               | QuantileLoss                    | 0     \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:1  | logging_metrics                    | ModuleList                      | 0     \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:3  | prescalers                         | ModuleDict                      | 256   \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:11 | lstm_encoder                       | LSTM                            | 2.2 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:12 | lstm_decoder                       | LSTM                            | 2.2 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:17 | post_attn_gate_norm                | GateAddNorm                     | 576   \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:19 | pre_output_gate_norm               | GateAddNorm                     | 576   \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:20 | output_layer                       | Linear                          | 119   \n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:29.7 K    Trainable params\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:0         Non-trainable params\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:29.7 K    Total params\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:0.119     Total estimated model params size (MB)\n",
      "Sanity Checking: 0it [00:00, ?it/s][1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2023-03-04 14:18:15.274 algo-1-rc30d:174 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2023-03-04 14:18:15.279 algo-1-rc30d:169 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2023-03-04 14:18:15.300 algo-1-rc30d:166 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:18:15.301 algo-1-rc30d:164 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:18:15.302 algo-1-rc30d:158 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2023-03-04 14:18:15.302 algo-1-rc30d:173 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:18:15.307 algo-1-rc30d:161 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:18:15.309 algo-1-rc30d:634 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:[2023-03-04 14:18:15.433 algo-1-rc30d:174 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:[2023-03-04 14:18:15.439 algo-1-rc30d:169 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:[2023-03-04 14:18:15.458 algo-1-rc30d:166 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:[2023-03-04 14:18:15.460 algo-1-rc30d:173 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:18:15.461 algo-1-rc30d:158 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:18:15.461 algo-1-rc30d:164 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:18:15.471 algo-1-rc30d:161 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:18:15.472 algo-1-rc30d:634 INFO profiler_config_parser.py:111] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "Sanity Checking DataLoader 0:   0% 0/1 [00:00<?, ?it/s]algo-1]<stdout>:\n",
      "Sanity Checking DataLoader 0: 100% 1/1 [00:00<00:00,  1.10it/s]:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Training: 0it [00:00, ?it/s] |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Training:   0% 0/2 [00:00<?, ?it/s][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 0:   0% 0/2 [00:00<?, ?it/s] [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  50% 1/2 [00:00<00:00,  1.89it/s]ank:0,algo-1]<stdout>:\n",
      "Epoch 0:  50% 1/2 [00:00<00:00,  1.89it/s, loss=268, v_num=0, train_loss_step=268.0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation: 0it [00:00, ?it/s]\u001b[Am [1,mpirank:0,algo-1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation:   0% 0/1 [00:00<?, ?it/s]\u001b[A[1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[A1]<stdout>:\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.47it/s]\u001b[A[1,mpirank:0,algo-1]<stdout>:\n",
      "Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.47it/s]\u001b[At>:\n",
      "Epoch 0: 100% 2/2 [00:00<00:00,  2.40it/s, loss=268, v_num=0, train_loss_step=268.0][1,mpirank:0,algo-1]<stdout>:\n",
      "Epoch 0: 100% 2/2 [00:01<00:00,  1.01it/s, loss=268, v_num=0, train_loss_step=268.0, val_loss=403.0][1,mpirank:0,algo-1]<stdout>:\n",
      "                                                          [1,mpirank:0,algo-1]<stdout>:\u001b[A\n",
      "Epoch 0: 100% 2/2 [00:01<00:00,  1.01it/s, loss=268, v_num=0, train_loss_step=268.0, val_loss=403.0, train_loss_epoch=337.0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:4,algo-1]<stdout>:\u001b[0m\n",
      "Epoch 0: 100% 2/2 [00:02<00:00,  1.07s/it, loss=268, v_num=0, train_loss_step=268.0, val_loss=403.0, train_loss_epoch=337.0]\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:6,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:7,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m [1,mpirank:5,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:18:21,337 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:18:21,337 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:18:21,338 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:18:51,368 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\n",
      "\u001b[36mn3a77bo8pk-algo-1-rc30d |\u001b[0m 2023-03-04 14:18:51,368 sagemaker-training-toolkit INFO     Reporting training SUCCESS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:creating /tmp/tmpflvadli6/artifacts/output/data\n",
      "INFO:root:copying /tmp/tmpflvadli6/algo-1-rc30d/output/success -> /tmp/tmpflvadli6/artifacts/output\n",
      "INFO:root:copying /tmp/tmpflvadli6/model/model.pth -> /tmp/tmpflvadli6/artifacts/model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36mn3a77bo8pk-algo-1-rc30d exited with code 0\n",
      "\u001b[0mAborting on container exit...\n",
      "===== Job Complete =====\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "if local_mode:\n",
    "    local_estimator = PyTorch(\n",
    "        entry_point=\"TFT_Train_SM_DDP.py\",    \n",
    "        source_dir='src',    \n",
    "        role=role,\n",
    "        framework_version='1.12.1',    \n",
    "        py_version='py38',        \n",
    "        distribution={\"pytorchddp\":{\"enabled\": True}},        \n",
    "        instance_count=1,\n",
    "        instance_type=instance_type, # local_gpu or local 지정\n",
    "        session = sagemaker.LocalSession(), # 로컬 세션을 사용합니다.\n",
    "        hyperparameters= hyperparameters               \n",
    "\n",
    "    )\n",
    "    local_estimator.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c07adc-d09c-41b0-b695-5275163bb916",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 3. SageMaker Cloud Mode\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "520d65d7-c008-430e-b2ad-88717f8a0f64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 파라미터 셋업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9672d08d-aebe-4d2e-bf76-5d500b71757f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#instance_type = 'ml.g4dn.12xlarge'\n",
    "instance_type = 'ml.p3.8xlarge'\n",
    "hyperparameters = {'epochs': epochs, \n",
    "                    }  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2c2ad1cd-6b9e-4f27-bcae-3a36cd404706",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:botocore.credentials:Found credentials from IAM Role: BaseNotebookInstanceEc2InstanceRole\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: pytorch-training-2023-03-04-14-18-52-747\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "import os\n",
    "\n",
    "\n",
    "estimator = PyTorch(\n",
    "    entry_point=\"TFT_Train_SM_DDP.py\",    \n",
    "    source_dir='src',    \n",
    "    role=role,\n",
    "    framework_version='1.12.1',    \n",
    "    py_version='py38',     \n",
    "    distribution={\"pytorchddp\":{\"enabled\": True}},    \n",
    "    instance_count=2,\n",
    "    instance_type=instance_type, # local_gpu or local 지정\n",
    "    session = sagemaker.Session(),\n",
    "    hyperparameters= hyperparameters               \n",
    "    \n",
    ")\n",
    "estimator.fit(wait=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e9e7371-b155-43ae-bcc7-ea6dee9ffe3d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-03-04 14:18:53 Starting - Starting the training job......\n",
      "2023-03-04 14:19:49 Starting - Preparing the instances for training.........\n",
      "2023-03-04 14:21:11 Downloading - Downloading input data\n",
      "2023-03-04 14:21:11 Training - Downloading the training image.....................\n",
      "2023-03-04 14:24:32 Training - Training image download completed. Training in progress..\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,023 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,059 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,071 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,074 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,074 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:24:49,320 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[34m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[34mCollecting pytorch-forecasting==0.10.3\u001b[0m\n",
      "\u001b[34mDownloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 5.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pytorch-lightning==1.6.3\u001b[0m\n",
      "\u001b[34mDownloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 584.0/584.0 kB 53.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow==11.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (11.0.0)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard==2.12.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 82.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy<2.0,>=1.8 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas<2.0.0,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.5.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.7.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch<2.0,>=1.7 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.12.1+cu113)\u001b[0m\n",
      "\u001b[34mCollecting statsmodels\u001b[0m\n",
      "\u001b[34mDownloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 85.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting optuna<3.0.0,>=2.3.0\u001b[0m\n",
      "\u001b[34mDownloading optuna-2.10.1-py3-none-any.whl (308 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.2/308.2 kB 46.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting scikit-learn<1.2,>=0.24\u001b[0m\n",
      "\u001b[34mDownloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.2/31.2 MB 49.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (23.0)\u001b[0m\n",
      "\u001b[34mCollecting torchmetrics>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 518.6/518.6 kB 56.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.64.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (1.23.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (2023.1.0)\u001b[0m\n",
      "\u001b[34mCollecting pyDeprecate<0.4.0,>=0.3.1\u001b[0m\n",
      "\u001b[34mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[34mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[35mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[35mbash: no job control in this shell\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,260 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,297 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,309 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,312 sagemaker_pytorch_container.training INFO     Invoking SMDataParallel for native PT DDP job\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,312 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:24:49,581 sagemaker-training-toolkit INFO     Installing dependencies from requirements.txt:\u001b[0m\n",
      "\u001b[35m/opt/conda/bin/python3.8 -m pip install -r requirements.txt\u001b[0m\n",
      "\u001b[35mCollecting pytorch-forecasting==0.10.3\u001b[0m\n",
      "\u001b[35mDownloading pytorch_forecasting-0.10.3-py3-none-any.whl (141 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 141.4/141.4 kB 5.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pytorch-lightning==1.6.3\u001b[0m\n",
      "\u001b[35mDownloading pytorch_lightning-1.6.3-py3-none-any.whl (584 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 584.0/584.0 kB 54.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyarrow==11.0.0 in /opt/conda/lib/python3.8/site-packages (from -r requirements.txt (line 5)) (11.0.0)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard==2.12.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.6/5.6 MB 80.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pandas<2.0.0,>=1.3.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.5.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: matplotlib in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.7.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: torch<2.0,>=1.7 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.12.1+cu113)\u001b[0m\n",
      "\u001b[35mCollecting scikit-learn<1.2,>=0.24\u001b[0m\n",
      "\u001b[35mDownloading scikit_learn-1.1.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31.2 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 31.2/31.2 MB 48.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting statsmodels\u001b[0m\n",
      "\u001b[35mDownloading statsmodels-0.13.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.9 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 9.9/9.9 MB 79.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: scipy<2.0,>=1.8 in /opt/conda/lib/python3.8/site-packages (from pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.10.0)\u001b[0m\n",
      "\u001b[35mCollecting optuna<3.0.0,>=2.3.0\u001b[0m\n",
      "\u001b[35mDownloading optuna-2.10.1-py3-none-any.whl (308 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 308.2/308.2 kB 48.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting pyDeprecate<0.4.0,>=0.3.1\u001b[0m\n",
      "\u001b[35mDownloading pyDeprecate-0.3.2-py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: packaging>=17.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (23.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: typing-extensions>=4.0.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.4.0)\u001b[0m\n",
      "\u001b[35mCollecting torchmetrics>=0.4.1\u001b[0m\n",
      "\u001b[35mDownloading torchmetrics-0.11.3-py3-none-any.whl (518 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 518.6/518.6 kB 64.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: numpy>=1.17.2 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (1.23.5)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fsspec[http]!=2021.06.0,>=2021.05.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (2023.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: PyYAML>=5.4 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (5.4.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: tqdm>=4.57.0 in /opt/conda/lib/python3.8/site-packages (from pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (4.64.1)\u001b[0m\n",
      "\u001b[35mCollecting grpcio>=1.48.2\u001b[0m\n",
      "\u001b[35mDownloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 92.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[35mDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 28.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.28.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (65.6.3)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (3.20.2)\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-data-server<0.8.0,>=0.7.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 94.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[35mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 67.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting google-auth-oauthlib<0.5,>=0.4.1\u001b[0m\n",
      "\u001b[35mDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\u001b[0m\n",
      "\u001b[34mCollecting grpcio>=1.48.2\u001b[0m\n",
      "\u001b[34mDownloading grpcio-1.51.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.8/4.8 MB 84.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (65.6.3)\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-data-server<0.8.0,>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_data_server-0.7.0-py3-none-manylinux2014_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 91.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (0.38.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.28.2)\u001b[0m\n",
      "\u001b[34mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[34mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 22.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.19.6 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (3.20.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.2.3)\u001b[0m\n",
      "\u001b[34mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[34mDownloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.2/177.2 kB 38.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting absl-py>=0.4\u001b[0m\n",
      "\u001b[34mDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 126.5/126.5 kB 31.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting tensorboard-plugin-wit>=1.6.0\u001b[0m\n",
      "\u001b[34mDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 781.3/781.3 kB 65.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting google-auth<3,>=1.6.3\u001b[0m\n",
      "\u001b[35mDownloading google_auth-2.16.2-py2.py3-none-any.whl (177 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 177.2/177.2 kB 30.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting markdown>=2.6.8\u001b[0m\n",
      "\u001b[35mDownloading Markdown-3.4.1-py3-none-any.whl (93 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.3/93.3 kB 20.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (0.38.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard==2.12.0->-r requirements.txt (line 6)) (2.2.3)\u001b[0m\n",
      "\u001b[35mCollecting aiohttp!=4.0.0a0,!=4.0.0a1\u001b[0m\n",
      "\u001b[35mDownloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 74.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[35mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[35mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 37.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.7.2)\u001b[0m\n",
      "\u001b[35mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[35mDownloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[35mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[35mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.13.0)\u001b[0m\n",
      "\u001b[35mCollecting cmaes>=0.8.2\u001b[0m\n",
      "\u001b[35mDownloading cmaes-0.9.1-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting aiohttp!=4.0.0a0,!=4.0.0a1\u001b[0m\n",
      "\u001b[34mDownloading aiohttp-3.8.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.0/1.0 MB 76.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting pyasn1-modules>=0.2.1\u001b[0m\n",
      "\u001b[34mDownloading pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 155.3/155.3 kB 36.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.9.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.16.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.7.2)\u001b[0m\n",
      "\u001b[34mCollecting cachetools<6.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading cachetools-5.3.0-py3-none-any.whl (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting requests-oauthlib>=0.7.0\u001b[0m\n",
      "\u001b[34mDownloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (4.13.0)\u001b[0m\n",
      "\u001b[34mCollecting cliff\u001b[0m\n",
      "\u001b[34mDownloading cliff-4.2.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 19.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cmaes>=0.8.2\u001b[0m\n",
      "\u001b[34mDownloading cmaes-0.9.1-py3-none-any.whl (21 kB)\u001b[0m\n",
      "\u001b[34mCollecting alembic\u001b[0m\n",
      "\u001b[34mDownloading alembic-1.9.4-py3-none-any.whl (210 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.5/210.5 kB 42.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting cliff\u001b[0m\n",
      "\u001b[35mDownloading cliff-4.2.0-py3-none-any.whl (81 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.0/81.0 kB 18.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting sqlalchemy>=1.1.0\u001b[0m\n",
      "\u001b[35mDownloading SQLAlchemy-2.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 91.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting alembic\u001b[0m\n",
      "\u001b[35mDownloading alembic-1.9.4-py3-none-any.whl (210 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 210.5/210.5 kB 42.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting colorlog\u001b[0m\n",
      "\u001b[35mDownloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2022.7.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.1)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.26.14)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2022.12.7)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.11.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (9.4.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.4.4)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (5.10.2)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (4.38.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.0.7)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.0.9)\u001b[0m\n",
      "\u001b[35mCollecting patsy>=0.5.2\u001b[0m\n",
      "\u001b[35mDownloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34mCollecting sqlalchemy>=1.1.0\u001b[0m\n",
      "\u001b[34mDownloading SQLAlchemy-2.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.8/2.8 MB 88.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting colorlog\u001b[0m\n",
      "\u001b[34mDownloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.8/site-packages (from pandas<2.0.0,>=1.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2022.7.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2022.12.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard==2.12.0->-r requirements.txt (line 6)) (1.26.14)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from scikit-learn<1.2,>=0.24->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.8/site-packages (from werkzeug>=1.0.1->tensorboard==2.12.0->-r requirements.txt (line 6)) (2.1.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (4.38.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.4.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (1.0.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (3.0.9)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.11.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: importlib-resources>=3.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (5.10.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.8/site-packages (from matplotlib->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (9.4.0)\u001b[0m\n",
      "\u001b[34mCollecting patsy>=0.5.2\u001b[0m\n",
      "\u001b[34mDownloading patsy-0.5.3-py2.py3-none-any.whl (233 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 33.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[34mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 233.8/233.8 kB 47.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (22.2.0)\u001b[0m\n",
      "\u001b[35mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[35mDownloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 26.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[35mDownloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 24.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting aiosignal>=1.1.2\u001b[0m\n",
      "\u001b[35mDownloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\u001b[0m\n",
      "\u001b[35mCollecting async-timeout<5.0,>=4.0.0a3\u001b[0m\n",
      "\u001b[35mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[35mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[35mDownloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 39.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting frozenlist>=1.1.1\u001b[0m\n",
      "\u001b[34mDownloading frozenlist-1.3.3-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (161 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 161.3/161.3 kB 36.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting multidict<7.0,>=4.5\u001b[0m\n",
      "\u001b[34mDownloading multidict-6.0.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (121 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.3/121.3 kB 27.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting yarl<2.0,>=1.0\u001b[0m\n",
      "\u001b[34mDownloading yarl-1.8.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (262 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 262.1/262.1 kB 46.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.8/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.6.3->-r requirements.txt (line 4)) (22.2.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.13.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard==2.12.0->-r requirements.txt (line 6)) (3.13.0)\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (0.4.8)\u001b[0m\n",
      "\u001b[35mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[35mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 23.1 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[35mCollecting Mako\u001b[0m\n",
      "\u001b[35mDownloading Mako-1.2.4-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 17.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting cmd2>=1.0.0\u001b[0m\n",
      "\u001b[35mDownloading cmd2-2.4.3-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.2/147.2 kB 24.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting autopage>=0.4.0\u001b[0m\n",
      "\u001b[35mDownloading autopage-0.5.1-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[35mCollecting stevedore>=2.0.1\u001b[0m\n",
      "\u001b[35mDownloading stevedore-5.0.0-py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 kB 12.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mCollecting PrettyTable>=0.7.2\u001b[0m\n",
      "\u001b[35mDownloading prettytable-3.6.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[35mCollecting pyperclip>=1.6\u001b[0m\n",
      "\u001b[35mDownloading pyperclip-1.8.2.tar.gz (20 kB)\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.12.0->-r requirements.txt (line 6)) (0.4.8)\u001b[0m\n",
      "\u001b[34mCollecting oauthlib>=3.0.0\u001b[0m\n",
      "\u001b[34mDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 151.7/151.7 kB 34.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.8/site-packages (from sqlalchemy>=1.1.0->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (2.0.2)\u001b[0m\n",
      "\u001b[34mCollecting Mako\u001b[0m\n",
      "\u001b[34mDownloading Mako-1.2.4-py3-none-any.whl (78 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.7/78.7 kB 20.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting stevedore>=2.0.1\u001b[0m\n",
      "\u001b[34mDownloading stevedore-5.0.0-py3-none-any.whl (49 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.6/49.6 kB 14.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting cmd2>=1.0.0\u001b[0m\n",
      "\u001b[34mDownloading cmd2-2.4.3-py3-none-any.whl (147 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 147.2/147.2 kB 36.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting autopage>=0.4.0\u001b[0m\n",
      "\u001b[34mDownloading autopage-0.5.1-py3-none-any.whl (29 kB)\u001b[0m\n",
      "\u001b[34mCollecting PrettyTable>=0.7.2\u001b[0m\n",
      "\u001b[34mDownloading prettytable-3.6.0-py3-none-any.whl (27 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyperclip>=1.6\u001b[0m\n",
      "\u001b[34mDownloading pyperclip-1.8.2.tar.gz (20 kB)\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): started\u001b[0m\n",
      "\u001b[35mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.2.6)\u001b[0m\n",
      "\u001b[35mCollecting pbr!=2.1.0,>=2.0.0\u001b[0m\n",
      "\u001b[35mDownloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[35m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.7/112.7 kB 26.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[35mBuilding wheels for collected packages: pyperclip\u001b[0m\n",
      "\u001b[35mBuilding wheel for pyperclip (setup.py): started\u001b[0m\n",
      "\u001b[34mPreparing metadata (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.8/site-packages (from cmd2>=1.0.0->cliff->optuna<3.0.0,>=2.3.0->pytorch-forecasting==0.10.3->-r requirements.txt (line 2)) (0.2.6)\u001b[0m\n",
      "\u001b[34mCollecting pbr!=2.1.0,>=2.0.0\u001b[0m\n",
      "\u001b[34mDownloading pbr-5.11.1-py2.py3-none-any.whl (112 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 112.7/112.7 kB 18.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: pyperclip\u001b[0m\n",
      "\u001b[34mBuilding wheel for pyperclip (setup.py): started\u001b[0m\n",
      "\u001b[35mBuilding wheel for pyperclip (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[35mCreated wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=31a57621e0c6b996bc1f318a6dca300fd6b150bbee2b45369c067102cd4c503d\u001b[0m\n",
      "\u001b[35mStored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\u001b[0m\n",
      "\u001b[35mSuccessfully built pyperclip\u001b[0m\n",
      "\u001b[34mBuilding wheel for pyperclip (setup.py): finished with status 'done'\u001b[0m\n",
      "\u001b[34mCreated wheel for pyperclip: filename=pyperclip-1.8.2-py3-none-any.whl size=11124 sha256=31a57621e0c6b996bc1f318a6dca300fd6b150bbee2b45369c067102cd4c503d\u001b[0m\n",
      "\u001b[34mStored in directory: /root/.cache/pip/wheels/7f/1a/65/84ff8c386bec21fca6d220ea1f5498a0367883a78dd5ba6122\u001b[0m\n",
      "\u001b[34mSuccessfully built pyperclip\u001b[0m\n",
      "\u001b[35mInstalling collected packages: tensorboard-plugin-wit, pyperclip, tensorboard-data-server, sqlalchemy, pyDeprecate, pyasn1-modules, PrettyTable, pbr, patsy, oauthlib, multidict, Mako, grpcio, frozenlist, colorlog, cmd2, cmaes, cachetools, autopage, async-timeout, absl-py, yarl, torchmetrics, stevedore, scikit-learn, requests-oauthlib, markdown, google-auth, alembic, aiosignal, statsmodels, google-auth-oauthlib, cliff, aiohttp, tensorboard, optuna, pytorch-lightning, pytorch-forecasting\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tensorboard-plugin-wit, pyperclip, tensorboard-data-server, sqlalchemy, pyDeprecate, pyasn1-modules, PrettyTable, pbr, patsy, oauthlib, multidict, Mako, grpcio, frozenlist, colorlog, cmd2, cmaes, cachetools, autopage, async-timeout, absl-py, yarl, torchmetrics, stevedore, scikit-learn, requests-oauthlib, markdown, google-auth, alembic, aiosignal, statsmodels, google-auth-oauthlib, cliff, aiohttp, tensorboard, optuna, pytorch-lightning, pytorch-forecasting\u001b[0m\n",
      "\u001b[35mAttempting uninstall: scikit-learn\u001b[0m\n",
      "\u001b[35mFound existing installation: scikit-learn 1.2.1\u001b[0m\n",
      "\u001b[35mUninstalling scikit-learn-1.2.1:\u001b[0m\n",
      "\u001b[35mSuccessfully uninstalled scikit-learn-1.2.1\u001b[0m\n",
      "\u001b[34mAttempting uninstall: scikit-learn\u001b[0m\n",
      "\u001b[34mFound existing installation: scikit-learn 1.2.1\u001b[0m\n",
      "\u001b[34mUninstalling scikit-learn-1.2.1:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled scikit-learn-1.2.1\u001b[0m\n",
      "\u001b[35mSuccessfully installed Mako-1.2.4 PrettyTable-3.6.0 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.9.4 async-timeout-4.0.2 autopage-0.5.1 cachetools-5.3.0 cliff-4.2.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 frozenlist-1.3.3 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 markdown-3.4.1 multidict-6.0.4 oauthlib-3.2.2 optuna-2.10.1 patsy-0.5.3 pbr-5.11.1 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pyperclip-1.8.2 pytorch-forecasting-0.10.3 pytorch-lightning-1.6.3 requests-oauthlib-1.3.1 scikit-learn-1.1.3 sqlalchemy-2.0.4 statsmodels-0.13.5 stevedore-5.0.0 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 torchmetrics-0.11.3 yarl-1.8.2\u001b[0m\n",
      "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[35m[notice] A new release of pip is available: 23.0 -> 23.0.1\u001b[0m\n",
      "\u001b[35m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,768 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,768 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,807 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,857 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,872 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,872 sagemaker-training-toolkit INFO     Waiting for MPI Master to create SSH daemon.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,873 sagemaker-training-toolkit INFO     Cannot connect to host algo-1\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:09,873 sagemaker-training-toolkit INFO     Connection failed with exception: \n",
      " [Errno None] Unable to connect to port 22 on 10.2.76.136.              Can be ignored for worker when master completes and exits.\u001b[0m\n",
      "\u001b[34mSuccessfully installed Mako-1.2.4 PrettyTable-3.6.0 absl-py-1.4.0 aiohttp-3.8.4 aiosignal-1.3.1 alembic-1.9.4 async-timeout-4.0.2 autopage-0.5.1 cachetools-5.3.0 cliff-4.2.0 cmaes-0.9.1 cmd2-2.4.3 colorlog-6.7.0 frozenlist-1.3.3 google-auth-2.16.2 google-auth-oauthlib-0.4.6 grpcio-1.51.3 markdown-3.4.1 multidict-6.0.4 oauthlib-3.2.2 optuna-2.10.1 patsy-0.5.3 pbr-5.11.1 pyDeprecate-0.3.2 pyasn1-modules-0.2.8 pyperclip-1.8.2 pytorch-forecasting-0.10.3 pytorch-lightning-1.6.3 requests-oauthlib-1.3.1 scikit-learn-1.1.3 sqlalchemy-2.0.4 statsmodels-0.13.5 stevedore-5.0.0 tensorboard-2.12.0 tensorboard-data-server-0.7.0 tensorboard-plugin-wit-1.8.1 torchmetrics-0.11.3 yarl-1.8.2\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.0 -> 23.0.1\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,880 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,881 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,919 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,969 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,984 sagemaker-training-toolkit INFO     Starting MPI run as worker node.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,984 sagemaker-training-toolkit INFO     Creating SSH daemon.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,986 sagemaker-training-toolkit INFO     Waiting for MPI workers to establish their SSH connections\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,987 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:09,987 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:10,885 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:11,054 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:11,055 sagemaker-training-toolkit INFO     Can connect to host algo-1\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:11,055 sagemaker-training-toolkit INFO     MPI Master online, creating SSH daemon.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:11,055 sagemaker-training-toolkit INFO     Writing environment variables to /etc/environment for the MPI process.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:11,059 sagemaker-training-toolkit INFO     Waiting for MPI process to finish.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:10,988 sagemaker-training-toolkit INFO     Cannot connect to host algo-2 at port 22. Retrying...\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:10,988 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,000 paramiko.transport INFO     Connected (version 2.0, client OpenSSH_8.2p1)\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,170 paramiko.transport INFO     Authentication (publickey) successful!\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,170 sagemaker-training-toolkit INFO     Can connect to host algo-2 at port 22\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,171 sagemaker-training-toolkit INFO     Connection closed\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,171 sagemaker-training-toolkit INFO     Worker algo-2 available for communication\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,171 sagemaker-training-toolkit INFO     Network interface name: eth0\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,171 sagemaker-training-toolkit INFO     Host: ['algo-1', 'algo-2']\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,172 sagemaker-training-toolkit INFO     sagemaker_communication_backend: None\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,172 sagemaker-training-toolkit WARNING  Missing library /opt/conda/lib/libsmddp.so for SMDDP collective\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,172 sagemaker-training-toolkit WARNING  The system is not configured to run SMDDP collectives optimizedfor AWS infrastructure.Please use the latest SageMaker Deep Learning Container (DLC) to enable SMDDP Collectives support.\u001b[0m\n",
      "\u001b[34mContinuing model training with default NCCL communication backend.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,172 sagemaker-training-toolkit INFO     instance type: ml.p3.8xlarge\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,172 sagemaker-training-toolkit INFO     Env Hosts: ['algo-1', 'algo-2'] Hosts: ['algo-1:4', 'algo-2:4'] process_per_hosts: 4 num_processes: 8\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,212 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:12,226 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {\n",
      "        \"sagemaker_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"sagemaker_pytorch_ddp_enabled\": true\n",
      "    },\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "    \"distribution_hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"distribution_instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\",\n",
      "        \"algo-2\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 1\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.8xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\",\n",
      "                \"algo-2\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": true,\n",
      "    \"job_name\": \"pytorch-training-2023-03-04-14-18-52-747\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-18-52-747/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"TFT_Train_SM_DDP\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 32,\n",
      "    \"num_gpus\": 4,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.8xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\",\n",
      "            \"algo-2\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.8xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\",\n",
      "                    \"algo-2\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"TFT_Train_SM_DDP.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":1}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=TFT_Train_SM_DDP.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={\"sagemaker_instance_type\":\"ml.p3.8xlarge\",\"sagemaker_pytorch_ddp_enabled\":true}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.8xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\",\"algo-2\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=TFT_Train_SM_DDP\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=32\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-18-52-747/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{\"sagemaker_instance_type\":\"ml.p3.8xlarge\",\"sagemaker_pytorch_ddp_enabled\":true},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\",\"algo-2\"],\"current_instance_type\":\"ml.p3.8xlarge\",\"distribution_hosts\":[\"algo-1\",\"algo-2\"],\"distribution_instance_groups\":[\"homogeneousCluster\"],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\",\"algo-2\"],\"hyperparameters\":{\"epochs\":1},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":true,\"job_name\":\"pytorch-training-2023-03-04-14-18-52-747\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-18-52-747/source/sourcedir.tar.gz\",\"module_name\":\"TFT_Train_SM_DDP\",\"network_interface_name\":\"eth0\",\"num_cpus\":32,\"num_gpus\":4,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.8xlarge\",\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_groups\":[{\"hosts\":[\"algo-1\",\"algo-2\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.8xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"TFT_Train_SM_DDP.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"1\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=1\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python38.zip:/opt/conda/lib/python3.8:/opt/conda/lib/python3.8/lib-dynload:/opt/conda/lib/python3.8/site-packages:/opt/conda/lib/python3.8/site-packages/smdebug-1.0.24b20230214-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument-3.4.2-py3.8.egg:/opt/conda/lib/python3.8/site-packages/pyinstrument_cext-0.2.4-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/flash_attn-0.1-py3.8-linux-x86_64.egg:/opt/conda/lib/python3.8/site-packages/einops-0.6.0-py3.8.egg\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34mmpirun --host algo-1:4,algo-2:4 -np 8 --allow-run-as-root --tag-output --oversubscribe -mca btl_tcp_if_include eth0 -mca oob_tcp_if_include eth0 -mca plm_rsh_no_tree_spawn 1 -mca pml ob1 -mca btl ^openib -mca orte_abort_on_non_zero_status 1 -mca btl_vader_single_copy_mechanism none -mca plm_rsh_num_concurrent 2 -x NCCL_SOCKET_IFNAME=eth0 -x NCCL_DEBUG=INFO -x LD_LIBRARY_PATH -x PATH -x SMDATAPARALLEL_USE_HOMOGENEOUS=1 -x FI_PROVIDER=efa -x RDMAV_FORK_SAFE=1 -x LD_PRELOAD=/opt/conda/lib/python3.8/site-packages/gethostname.cpython-38-x86_64-linux-gnu.so -x SMDATAPARALLEL_SERVER_ADDR=algo-1 -x SMDATAPARALLEL_SERVER_PORT=7592 -x SAGEMAKER_INSTANCE_TYPE=ml.p3.8xlarge -x USE_SMDDP_COLLECTIVES=0 smddprun /opt/conda/bin/python3.8 -m mpi4py TFT_Train_SM_DDP.py --epochs 1\u001b[0m\n",
      "\u001b[34mWarning: Permanently added 'algo-2,10.2.83.126' (ECDSA) to the list of known hosts.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:16,071 sagemaker-training-toolkit INFO     Process[es]: [psutil.Process(pid=96, name='orted', status='sleeping', started='14:25:14')]\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:16,072 sagemaker-training-toolkit INFO     Orted process found [psutil.Process(pid=96, name='orted', status='sleeping', started='14:25:14')]\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:16,072 sagemaker-training-toolkit INFO     Waiting for orted process [psutil.Process(pid=96, name='orted', status='sleeping', started='14:25:14')]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:curl: /opt/conda/lib/libcurl.so.4: no version information available (required by curl)\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:Not running on notebook\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:***** Arguments *****\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:epochs=1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:seed=100\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:train_batch_size=64\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:model_dir=/opt/ml/model\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:n_gpus=4\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:num_nodes=19\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:world_size=76\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 5, MEMBER: 6/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 4, MEMBER: 5/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 6, MEMBER: 7/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stderr>:Initializing distributed: GLOBAL_RANK: 7, MEMBER: 8/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:GPU available: True, used: True\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:TPU available: False, using: 0 TPU cores\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:IPU available: False, using: 0 IPUs\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:HPU available: False, using: 0 HPUs\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:Number of parameters in network: 29.7k\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 3, MEMBER: 4/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 1, MEMBER: 2/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Initializing distributed: GLOBAL_RANK: 2, MEMBER: 3/8\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:distributed_backend=nccl\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:All distributed processes registered. Starting with 8 processes\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stderr>:Missing logger folder: lightning_logs/lightning_logs\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO Bootstrap : Using eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:NCCL version 2.10.3+cuda11.3\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO Bootstrap : Using eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO Bootstrap : Using eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:167 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:169 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO Bootstrap : Using eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.76.136<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:171 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO Bootstrap : Using eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO NET/Socket : Using [0]eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:248 [0] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO Bootstrap : Using eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO NET/Socket : Using [0]eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:136 [2] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO Bootstrap : Using eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO Bootstrap : Using eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO NET/Plugin: Failed to find ncclCollNetPlugin_v4 symbol.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO NET/OFI Using aws-ofi-nccl 1.3.0aws\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO NET/OFI Setting FI_EFA_FORK_SAFE environment variable to 1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO NET/Socket : Using [0]eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:134 [1] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] find_ofi_provider:608 NCCL WARN NET/OFI Couldn't find any optimal provider\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] ofi_init:1339 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO NCCL_IB_DISABLE set by environment to 1.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO NET/Socket : Using [0]eth0:10.2.83.126<0>\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:138 [3] NCCL INFO Using network Socket\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Trees [0] -1/-1/-1->3->2 [1] -1/-1/-1->3->2\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Trees [0] 3/-1/-1->2->1 [1] 3/-1/-1->2->1\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Trees [0] 2/-1/-1->1->0 [1] 2/-1/-1->1->0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 00/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 01/02 :    0   1   2   3   4   5   6   7\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Trees [0] 1/4/-1->0->-1 [1] 1/-1/-1->0->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Trees [0] 5/-1/-1->4->0 [1] 5/0/-1->4->-1\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Trees [0] 6/-1/-1->5->4 [1] 6/-1/-1->5->4\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Trees [0] 7/-1/-1->6->5 [1] 7/-1/-1->6->5\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Trees [0] -1/-1/-1->7->6 [1] -1/-1/-1->7->6\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Channel 00 : 2[1d0] -> 3[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Channel 00 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Channel 00 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Channel 01 : 2[1d0] -> 3[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Channel 00 : 1[1c0] -> 2[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Channel 01 : 6[1d0] -> 7[1e0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Channel 01 : 5[1c0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Channel 01 : 1[1c0] -> 2[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 00 : 3[1e0] -> 4[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Channel 00 : 7[1e0] -> 0[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Channel 00 : 3[1e0] -> 4[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 00 : 7[1e0] -> 0[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 01 : 3[1e0] -> 4[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 00 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 01 : 4[1b0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Channel 01 : 7[1e0] -> 0[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Channel 01 : 3[1e0] -> 4[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 01 : 7[1e0] -> 0[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 00 : 0[1b0] -> 1[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 01 : 0[1b0] -> 1[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Channel 00 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Channel 00 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Channel 00 : 2[1d0] -> 1[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Channel 01 : 5[1c0] -> 4[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Channel 01 : 6[1d0] -> 5[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Channel 01 : 2[1d0] -> 1[1c0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Channel 00 : 1[1c0] -> 0[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Channel 00 : 3[1e0] -> 2[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Connected all rings\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Channel 01 : 1[1c0] -> 0[1b0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Channel 01 : 3[1e0] -> 2[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Channel 00 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Channel 01 : 7[1e0] -> 6[1d0] via P2P/IPC\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 00 : 0[1b0] -> 4[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 00 : 4[1b0] -> 0[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 01 : 0[1b0] -> 4[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 01 : 4[1b0] -> 0[1b0] [receive] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO NET/Socket: Using 2 threads and 8 sockets per thread\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 00 : 4[1b0] -> 0[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 00 : 0[1b0] -> 4[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Channel 01 : 4[1b0] -> 0[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Channel 01 : 0[1b0] -> 4[1b0] [send] via NET/Socket/0\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO Connected all trees\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO threadThresholds 8/8/64 | 64/8/64 | 8/8/512\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO 2 coll channels, 2 p2p channels, 1 p2p channels per peer\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:algo-1:171:501 [2] NCCL INFO comm 0x7fb388003010 rank 2 nranks 8 cudaDev 2 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:algo-1:169:500 [3] NCCL INFO comm 0x7f45cc003010 rank 3 nranks 8 cudaDev 3 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:498 [0] NCCL INFO comm 0x7fe680003010 rank 0 nranks 8 cudaDev 0 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:algo-1:167:499 [1] NCCL INFO comm 0x7fbcc8003010 rank 1 nranks 8 cudaDev 1 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:algo-2:248:462 [0] NCCL INFO comm 0x7facb4003010 rank 4 nranks 8 cudaDev 0 busId 1b0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:algo-2:138:465 [3] NCCL INFO comm 0x7f74a4003010 rank 7 nranks 8 cudaDev 3 busId 1e0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:algo-2:136:463 [2] NCCL INFO comm 0x7f21ec003010 rank 6 nranks 8 cudaDev 2 busId 1d0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:algo-2:134:464 [1] NCCL INFO comm 0x7f3358003010 rank 5 nranks 8 cudaDev 1 busId 1c0 - Init COMPLETE\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:algo-1:281:281 [0] NCCL INFO Launch mode Parallel\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stderr>:LOCAL_RANK: 3 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stderr>:LOCAL_RANK: 2 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stderr>:LOCAL_RANK: 1 - CUDA_VISIBLE_DEVICES: [0,1,2,3]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:   | Name                               | Type                            | Params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:0  | loss                               | QuantileLoss                    | 0     \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:1  | logging_metrics                    | ModuleList                      | 0     \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:2  | input_embeddings                   | MultiEmbedding                  | 1.3 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:3  | prescalers                         | ModuleDict                      | 256   \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:4  | static_variable_selection          | VariableSelectionNetwork        | 3.4 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:5  | encoder_variable_selection         | VariableSelectionNetwork        | 8.0 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:6  | decoder_variable_selection         | VariableSelectionNetwork        | 2.7 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:7  | static_context_variable_selection  | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:8  | static_context_initial_hidden_lstm | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:9  | static_context_initial_cell_lstm   | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:10 | static_context_enrichment          | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:11 | lstm_encoder                       | LSTM                            | 2.2 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:12 | lstm_decoder                       | LSTM                            | 2.2 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:13 | post_lstm_gate_encoder             | GatedLinearUnit                 | 544   \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:14 | post_lstm_add_norm_encoder         | AddNorm                         | 32    \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:15 | static_enrichment                  | GatedResidualNetwork            | 1.4 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:16 | multihead_attn                     | InterpretableMultiHeadAttention | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:17 | post_attn_gate_norm                | GateAddNorm                     | 576   \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:18 | pos_wise_ff                        | GatedResidualNetwork            | 1.1 K \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:19 | pre_output_gate_norm               | GateAddNorm                     | 576   \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:20 | output_layer                       | Linear                          | 119   \u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:----------------------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:29.7 K    Trainable params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:0         Non-trainable params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:29.7 K    Total params\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:0.119     Total estimated model params size (MB)\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.481 algo-2:136 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.495 algo-2:134 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.497 algo-2:138 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.506 algo-1:169 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.507 algo-1:281 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.507 algo-1:171 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.514 algo-2:248 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.520 algo-1:167 INFO utils.py:28] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.640 algo-2:136 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.642 algo-2:136 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.642 algo-2:136 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.642 algo-2:136 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:[2023-03-04 14:25:28.643 algo-2:136 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.657 algo-2:134 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.658 algo-2:134 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.658 algo-2:138 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.658 algo-2:134 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.659 algo-2:134 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:[2023-03-04 14:25:28.659 algo-2:134 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.660 algo-2:138 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.660 algo-2:138 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.661 algo-2:138 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:[2023-03-04 14:25:28.661 algo-2:138 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.666 algo-1:169 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.666 algo-1:281 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.667 algo-1:169 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.667 algo-1:169 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.668 algo-1:281 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.668 algo-1:281 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.668 algo-1:169 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:[2023-03-04 14:25:28.668 algo-1:169 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.669 algo-1:281 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:[2023-03-04 14:25:28.669 algo-1:281 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.671 algo-1:171 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.672 algo-1:171 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.673 algo-1:171 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.673 algo-1:171 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:[2023-03-04 14:25:28.673 algo-1:171 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.676 algo-2:248 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking:   0% 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking DataLoader 0:   0% 0/1 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.678 algo-2:248 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.678 algo-2:248 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.679 algo-2:248 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:[2023-03-04 14:25:28.679 algo-2:248 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.679 algo-1:167 INFO profiler_config_parser.py:111] User has disabled profiler.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.681 algo-1:167 INFO json_config.py:92] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.681 algo-1:167 INFO hook.py:206] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.682 algo-1:167 INFO hook.py:259] Saving to /opt/ml/output/tensors\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:[2023-03-04 14:25:28.682 algo-1:167 INFO state_store.py:77] The checkpoint config file /opt/ml/input/config/checkpointconfig.json does not exist.\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Sanity Checking DataLoader 0: 100% 1/1 [00:00<00:00,  1.59it/s][1,mpirank:0,algo-1]<stdout>:#015Sanity Checking DataLoader 0: 100% 1/1 [00:00<00:00,  1.59it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Training: 0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Training:   0% 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:   0% 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stderr>:[W reducer.cpp:1251] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:00<00:01,  1.68it/s][1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:00<00:01,  1.68it/s]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  33% 1/3 [00:00<00:01,  1.68it/s, loss=372, v_num=0, train_loss_step=372.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  67% 2/3 [00:00<00:00,  2.35it/s, loss=372, v_num=0, train_loss_step=372.0][1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  67% 2/3 [00:00<00:00,  2.35it/s, loss=372, v_num=0, train_loss_step=372.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0:  67% 2/3 [00:00<00:00,  2.35it/s, loss=409, v_num=0, train_loss_step=446.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation: 0it [00:00, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0:   0% 0/1 [00:00<?, ?it/s]#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.25it/s]#033[A[1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Validation DataLoader 0: 100% 1/1 [00:00<00:00,  3.25it/s]#033[A[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:01<00:00,  2.55it/s, loss=409, v_num=0, train_loss_step=446.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:01<00:00,  2.55it/s, loss=409, v_num=0, train_loss_step=446.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:01<00:00,  1.56it/s, loss=409, v_num=0, train_loss_step=446.0, val_loss=343.0][1,mpirank:0,algo-1]<stdout>:\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015                                                          [1,mpirank:0,algo-1]<stdout>:#033[A\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:01<00:00,  1.55it/s, loss=409, v_num=0, train_loss_step=446.0, val_loss=343.0, train_loss_epoch=331.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:2,algo-1]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:1,algo-1]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:4,algo-2]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:3,algo-1]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:7,algo-2]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:6,algo-2]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:5,algo-2]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#015Epoch 0: 100% 3/3 [00:02<00:00,  1.45it/s, loss=409, v_num=0, train_loss_step=446.0, val_loss=343.0, train_loss_epoch=331.0]\u001b[0m\n",
      "\u001b[34m[1,mpirank:0,algo-1]<stdout>:#033[0m\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,674 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,674 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,674 sagemaker-training-toolkit INFO     Begin writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,674 sagemaker-training-toolkit INFO     Start writing mpirun finished status to algo-2\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,835 sagemaker-training-toolkit INFO     output from subprocess run CompletedProcess(args=['ssh', 'algo-2', 'touch', '/tmp/done.algo-1'], returncode=0, stdout='', stderr='')\u001b[0m\n",
      "\u001b[34m2023-03-04 14:25:33,835 sagemaker-training-toolkit INFO     Finished writing status file\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:33,689 sagemaker-training-toolkit INFO     Invoked on_terminate from psutil.wait_for_procs\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:33,689 sagemaker-training-toolkit INFO     process psutil.Process(pid=96, name='orted', status='terminated', started='14:25:14') terminated with exit code None\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:33,689 sagemaker-training-toolkit INFO     Reporting status for ORTEd process. gone: [psutil.Process(pid=96, name='orted', status='terminated', started='14:25:14')] alive: []\u001b[0m\n",
      "\u001b[35m2023-03-04 14:25:33,689 sagemaker-training-toolkit INFO     Orted process exited\u001b[0m\n",
      "\u001b[35m2023-03-04 14:26:03,717 sagemaker-training-toolkit INFO     Begin looking for status file on algo-2\u001b[0m\n",
      "\u001b[35m2023-03-04 14:26:03,717 sagemaker-training-toolkit INFO     MPI training job status file found. Exit gracefully\u001b[0m\n",
      "\u001b[35m2023-03-04 14:26:03,717 sagemaker-training-toolkit INFO     End looking for status file\u001b[0m\n",
      "\u001b[35m2023-03-04 14:26:03,717 sagemaker-training-toolkit INFO     MPI process finished.\u001b[0m\n",
      "\u001b[35m2023-03-04 14:26:03,718 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\u001b[34m2023-03-04 14:26:03,862 sagemaker-training-toolkit INFO     Finished writing status file from leader node to worker nodes\u001b[0m\n",
      "\u001b[34m2023-03-04 14:26:03,862 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2023-03-04 14:26:24 Uploading - Uploading generated training model\n",
      "2023-03-04 14:26:24 Completed - Training job completed\n",
      "Training seconds: 656\n",
      "Billable seconds: 656\n"
     ]
    }
   ],
   "source": [
    "estimator.logs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68fc8308-d46e-4017-82d4-5d5b0288b2c2",
   "metadata": {},
   "source": [
    "# 4. 모델 가중치 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aad560bd-200f-46af-8548-e4506cb55265",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model artifact: \n",
      " s3://sagemaker-us-east-1-057716757052/pytorch-training-2023-03-04-14-18-52-747/output/model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "print(\"model artifact: \\n\", estimator.model_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3564849c-9754-4a10-b417-86ec80a74d0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f6d331-3d30-467d-a982-ae1ec9b5b7e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
