### 체계적인 8주 커리큘럼.

### 





![img](https://cdn.www.fastcampus.co.kr/wp-content/uploads/2018/07/step.png)



#### **PART 1. HADOOP 기초와 빅데이터 플랫폼의 개념 및 설계**



#### 1회차: 빅데이터 플랫폼과 하둡 에코시스템(HADOOP ECOSYSTEM) 기술▼



**빅데이터 분석의 근간이 되는 빅데이터 플랫폼의 개념을 이해합니다.**
**데이터 수집, 저장, 처리, 분석에 필요한 다양한 Hadoop Ecosystem을 살펴보고, Hadoop의 기본 작동원리를 배웁니다.**

– 빅데이터 플랫폼의 이해
– Hadoop Ecosystem 기술의 이해
– 하둡분산파일시스템(HDFS)의 구현원리
– 하둡맵리듀스(MapReduce)의 이해



#### 2회차: 빅데이터 플랫폼 구축 계획▼



**빅데이터 플랫폼의 아키텍처를 알아보고, 이를 바탕으로 실제 빅데이터 플랫폼을 어떻게 설계해야 하는지에 대해 배웁니다.**
**하드웨어나 네트워크 등 빅데이터 플랫폼을 도입할 때 필요한 것과 고려해야 할 사항들을 살펴봅니다.**

– 빅데이터 플랫폼 설계 방안
– H/W와 N/W 인프라 구성 및 설계
– 빅데이터 플랫폼 구축 프로세스와 설치

#### **PART 2. HADOOP을 이용한 빅데이터 플랫폼 구축**



#### 3회차: HADOOP ECOSYSTEM 의사모드(STANDALONE) 설치 (1대)▼



**버츄얼 박스(Virtual Box)를 이용하여 가상머신 생성 및 리눅스 CentOS 6.x 32비트 버전 설치 등 실습환경을 구성합니다.**
**의사모드로 Hadoop Ecosystem을 설치해보고 Hadoop의 기본적인 사용법을 익혀봅니다.**

– 가상화 환경, 가상 머신 준비
– Apache Hadoop 기반의 Hadoop Ecosystem 설치
– Hadoop 기본 사용법(하둡 환경설정, 코어 설정, HDFS 설정, MapReduce 2.0 설정, YARN 설정, 하둡 로그 설정 등)



#### 4회차: 완전분산모드(3대, 클러스터) APACHE HADOOP 설치 ▼



**분산처리에 필요한 리눅스 CentOS 7.x 64비트 버전을 설치하고 리눅스와 Apache Hadoop의 환경설정을 합니다.**
**다수의 리눅스 가상머신을 복제하여 네트워크 등을 설정하고, 클러스터링한 후 분산처리를 해봅니다.**

– 가상머신 복제(3대, 5대) 및 클러스터 설정
– Apache Hadoop 2.X 설치

#### **PART 3. 효율적인 데이터 처리와 분석을 위한 HADOOP ECOSYSTEM**



#### 5회차: HADOOP 기반 데이터웨어하우스(DATAWAREHOUSE) ▼



**Hadoop에는 MPP(Massively Parallel Processing)가 가능한 대용량 DB인 DW가 있습니다.** 
**이러한 Hadoop 기반 DW에서 SQL을 사용하기 위한 Hive와 Presto를 배웁니다.**

– Hadoop에서 SQL을 사용할 수 있게 해주는 Apache Hive의 이해와 실습
– SQL On Hadoop 기술의 이해
– Apache Hive보다 10배 빠른 SQL On Hadoop, Presto의 이해와 실습



#### 6회차: 빠른 데이터 분석을 위한 SPARK ▼



**기존 Hadoop의 단점들을 보완하는 Spark의 개념 및 아키텍처를 이해합니다.**
**Spark의 기본적인 사용법과 Hadoop과의 연동방법을 배우고, 이를 통해 분산처리 속도를 극대화합니다.**

– Spark vs MapReduce
– Spark 아키텍처의 이해
– Spark 클러스터 모드 설치 및 실습



#### 7회차: 실시간 처리 및 분석 시스템 ▼



**실시간 처리와 분석을 위한 Zookeeper, HBase, Elastic Stack의 기본개념을** 이해합니다.법과 **Hadoop과의 연동방법을 배우고, 이를 통해 분산처리 속도를 극대화합니다.**

– 분산환경 조정에 필요한 서비스를 제공하는 분산코디네이터, Zookeeper
– 비정형 데이터 처리(NoSQL)를 위한 컬럼기반 DB, HBase
– 오픈소스 실시간 분석 시스템, Elastic Stack

#### **PART 4. 실전 빅데이터 분석 프로젝트**



#### 8회차: HADOOP ECOSYSTEM 기반의 미니 프로젝트 수행 ▼



**7주 동안 배운 내용을 바탕으로 Hadoop, Hive, Presto, Spark을 이용하여 데이터를 적재하고 전처리한 후 분석하는 프로젝트를 수행합니다. LAMP(Linux, Apache, MySQL, PHP)를 이용하여 실제 웹 서비스를 구현해보고, 이를 통해 빅데이터 분석이 어떻게 실제 제품으로 만들어지는지 경험합니다.**

– 데이터 적재 및 전처리
– SQL On Hadoop을 이용한 데이터 분석(연관규칙분석 등)
– LAMP(Linux, Apache, MySQL, PHP) 웹 서비스 구현